services:
  qwen30b-quantized:
    image: nvcr.io/nvidia/vllm:25.09-py3
    container_name: qwen30b-quantized

    network_mode: "host"
    ipc: "host"

    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - HF_HOME=/root/.cache/huggingface
      - VLLM_ATTENTION_BACKEND=FLASHINFER

    shm_size: "16g"
    ulimits:
      memlock: -1
      stack: 67108864

    volumes:
      - ./hf-cache:/root/.cache/huggingface
      - ./vllm-cache:/root/.cache/vllm

    command: >
      python -m vllm.entrypoints.openai.api_server
        --model RedHatAI/Qwen3-30B-A3B-quantized.w4a16
        --host 0.0.0.0
        --port 8000
        --dtype auto
        --tensor-parallel-size 1
        --max-model-len 4096
        --gpu-memory-utilization 0.3
        --swap-space 16
        --max-num-seqs 2
        --enable-auto-tool-choice
        --tool-call-parser qwen3_coder

    restart: unless-stopped